{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from functools import partial\n",
    "# from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Keras modules\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, layers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Pre-process the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Digit_Dataset_Full_Train_Labels.csv', 'Digit_Dataset_Full.mat', 'Digit_Dataset_Half.mat', 'Digit_Dataset_Half_Labels.csv', 'Digit_Dataset_Full_Test_Labels.csv']\n",
      "X_train_orig shape: (28, 28, 1, 9000)\n",
      "X_test_orig shape: (28, 28, 1, 1000)\n",
      "Y_train_orig shape: (9000,)\n",
      "Y_test_orig shape: (1000,) \n",
      "\n",
      "X_train shape: (9000, 28, 28, 1)\n",
      "X_test shape: (1000, 28, 28, 1)\n",
      "Y_train shape: (9000, 10)\n",
      "Y_test shape: (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('../input/'))\n",
    "\n",
    "# Load the datasets\n",
    "sample_full_data = loadmat('../input/Digit_Dataset_Full.mat')\n",
    "label_train_data = pd.read_csv(\"../input/Digit_Dataset_Full_Train_Labels.csv\")\n",
    "label_test_data = pd.read_csv(\"../input/Digit_Dataset_Full_Test_Labels.csv\")\n",
    "\n",
    "# Get data from the datasets\n",
    "X_train_orig = sample_full_data['Image'][0, 0][0]\n",
    "X_test_orig = sample_full_data['Image'][0, 0][1]\n",
    "Y_train_orig = label_train_data.values[:, 0]\n",
    "Y_test_orig = label_test_data.values[:, 0]\n",
    "\n",
    "# Print details of the orignal data\n",
    "print(\"X_train_orig shape: \" + str(X_train_orig.shape))\n",
    "print(\"X_test_orig shape: \" + str(X_test_orig.shape))\n",
    "print(\"Y_train_orig shape: \" + str(Y_train_orig.shape))\n",
    "print(\"Y_test_orig shape: \" + str(Y_test_orig.shape), \"\\n\")\n",
    "\n",
    "# Reshape the input data for keras\n",
    "split_fraction = 0.9     # should be greater than 0.5\n",
    "train_set_len = math.ceil((X_train_orig.shape[3] + X_test_orig.shape[3]) * split_fraction)\n",
    "test_set_len = X_train_orig.shape[3] + X_test_orig.shape[3] - train_set_len\n",
    "X_train = np.zeros((train_set_len, X_train_orig.shape[0], X_train_orig.shape[1], X_train_orig.shape[2]))\n",
    "X_test = np.zeros((test_set_len, X_train_orig.shape[0], X_train_orig.shape[1], X_train_orig.shape[2]))\n",
    "Y_train = np.zeros((train_set_len, 1))\n",
    "Y_test = np.zeros((test_set_len, 1))\n",
    "\n",
    "# Split into train and test, by the given split fraction\n",
    "for i in range(train_set_len + test_set_len):\n",
    "    if i < train_set_len:\n",
    "        if i < X_train_orig.shape[3]:\n",
    "            X_train[i] = X_train_orig[:, :, :, i]\n",
    "            Y_train[i] = Y_train_orig[i]\n",
    "        else:\n",
    "            X_train[i] = X_test_orig[:, :, :, i - X_train_orig.shape[3]]\n",
    "            Y_train[i] = Y_test_orig[i - X_train_orig.shape[3]]\n",
    "        \n",
    "    else:\n",
    "        if i < X_train_orig.shape[3]:\n",
    "            X_test[i - train_set_len] = X_train_orig[:, :, :, i]\n",
    "            Y_test[i - train_set_len] = Y_train_orig[i]\n",
    "        else:\n",
    "            X_test[i - train_set_len] = X_test_orig[:, :, :, i - X_train_orig.shape[3]]\n",
    "            Y_test[i - train_set_len] = Y_test_orig[i - X_train_orig.shape[3]]\n",
    "\n",
    "# Convert the integer labels into one-hot\n",
    "Y_train = to_categorical(Y_train, num_classes=10, dtype='float32')\n",
    "Y_test = to_categorical(Y_test, num_classes=10, dtype='float32')\n",
    "\n",
    "# Print details of the reshaped data\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n",
    "# Pickle the preprocessed dataset\n",
    "# file_name = [\"X_Digit_Train.data\", \"Y_Digit_Train.data\", \"X_Digit_Test.data\", \"Y_Digit_Test.data\"]\n",
    "# dataset = [X_train, Y_train, X_test, Y_test]\n",
    "# for i, j in enumerate(file_name):\n",
    "#     with open(j, 'wb') as fileObject:\n",
    "#         pickle.dump(dataset[i] ,fileObject)\n",
    "\n",
    "# Create an image generator class\n",
    "imgGentrain = ImageDataGenerator()\n",
    "imgGentest = ImageDataGenerator()\n",
    "\n",
    "train_batch = imgGentrain.flow(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=1)\n",
    "test_batch = imgGentest.flow(\n",
    "    x=X_test,\n",
    "    y=Y_test,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 3600    # just some random image for preview\n",
    "plt.imshow(X_train[index, :, :, 0])\n",
    "print(\"y = \" + str(np.squeeze(Y_train[index, :])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr=0.001, beta_1=0.9, dropout=False):\n",
    "    # Delete the previous model, if there exists any\n",
    "    try: del model\n",
    "    except: pass\n",
    "\n",
    "    # Create a new model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add a convolutional layer\n",
    "    model.add(Conv2D(filters=20, kernel_size=5, strides=(1, 1), padding='valid', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "    # Add dropout, if dropout variable is set to True\n",
    "    if dropout: model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    # Flatten the output\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Add a dense layer\n",
    "    model.add(Dense(10))\n",
    "    model.add(layers.Softmax())\n",
    "    optAdam = optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer=optAdam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Dropout Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 7.9990 - acc: 0.3693\n",
      "Epoch 2/3\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.9847 - acc: 0.7014\n",
      "Epoch 3/3\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.4588 - acc: 0.8445\n",
      "Test loss: 0.14666560244560242\n",
      "Test accuracy: 0.956\n",
      "Accuracy when using dropout is 0.956 \n",
      "\n",
      "Epoch 1/3\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 11.8319 - acc: 0.2500\n",
      "Epoch 2/3\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 9.7031 - acc: 0.3849\n",
      "Epoch 3/3\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 8.7062 - acc: 0.4478\n",
      "Test loss: 8.582340234692612\n",
      "Test accuracy: 0.45\n",
      "Accuracy when not using dropout is 0.45 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fit_with(lr=0.001, beta_1=0.9, dropout=False):\n",
    "    # Create the model using a specified hyperparameters.\n",
    "    model = create_model(lr=lr, beta_1=beta_1, dropout=dropout)\n",
    "    \n",
    "    # Train the model with the train dataset.\n",
    "    model.fit_generator(\n",
    "        generator=train_batch,\n",
    "        steps_per_epoch=len(train_batch),\n",
    "        epochs=3)\n",
    "    \n",
    "    # print the test accuracy\n",
    "    score = model.evaluate(X_test, Y_test, verbose = 0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    # return the test accuracy\n",
    "    return score[1]\n",
    "\n",
    "# Print the training results\n",
    "dropout_list = [True, False]\n",
    "for drop in dropout_list:\n",
    "    print(\"Accuracy when\", \"using\" if drop else \"not using\" ,\"dropout is\", fit_with(dropout=drop), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
