{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Keras modules\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_orig shape: (28, 28, 1, 1000)\n",
      "X_test_orig shape: (28, 28, 1, 1000)\n",
      "Y_train_orig shape: (1000,)\n",
      "Y_test_orig shape: (1000,) \n",
      "\n",
      "X_train shape: (1000, 28, 28, 1)\n",
      "X_test shape: (1000, 28, 28, 1)\n",
      "Y_train shape: (1000, 10)\n",
      "Y_test shape: (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the datasets\n",
    "sample_data = loadmat('Digit_Dataset.mat')\n",
    "label_data = pd.read_csv(\"Digit_Dataset_Labels.csv\")\n",
    "\n",
    "# Get data from the datasets\n",
    "X_train_orig = sample_data['Image'][0, 0][0]\n",
    "X_test_orig = sample_data['Image'][0, 0][1]\n",
    "Y_train_orig = label_data.values[:, 0]\n",
    "Y_test_orig = label_data.values[:, 1]\n",
    "\n",
    "# Print details of the orignal data\n",
    "print(\"X_train_orig shape: \" + str(X_train_orig.shape))\n",
    "print(\"X_test_orig shape: \" + str(X_test_orig.shape))\n",
    "print(\"Y_train_orig shape: \" + str(Y_train_orig.shape))\n",
    "print(\"Y_test_orig shape: \" + str(Y_test_orig.shape), \"\\n\")\n",
    "\n",
    "# Reshape the input data for keras\n",
    "split_fraction = 0.5     # should be greater than 0.5\n",
    "train_set_len = math.ceil((X_train_orig.shape[3] + X_test_orig.shape[3]) * split_fraction)\n",
    "test_set_len = X_train_orig.shape[3] + X_test_orig.shape[3] - math.floor((X_train_orig.shape[3] + X_test_orig.shape[3]) * split_fraction)\n",
    "X_train = np.zeros((train_set_len, X_train_orig.shape[0], X_train_orig.shape[1], X_train_orig.shape[2]))\n",
    "X_test = np.zeros((test_set_len, X_train_orig.shape[0], X_train_orig.shape[1], X_train_orig.shape[2]))\n",
    "Y_train = np.zeros((train_set_len, 1))\n",
    "Y_test = np.zeros((test_set_len, 1))\n",
    "\n",
    "for i in range(train_set_len + test_set_len):\n",
    "    if i < train_set_len:\n",
    "        try:\n",
    "            X_train[i] = X_train_orig[:, :, :, i]\n",
    "        except:\n",
    "            X_train[i] = X_test_orig[:, :, :, i - train_set_len]  \n",
    "\n",
    "        try:\n",
    "            Y_train[i] = Y_train_orig[i]\n",
    "        except:\n",
    "            Y_train[i] = Y_test_orig[i - train_set_len]\n",
    "    else:\n",
    "        X_test[i - train_set_len] = X_test_orig[:, :, :, i - train_set_len]\n",
    "        Y_test[i - train_set_len] = Y_test_orig[i - train_set_len]\n",
    "Y_train = to_categorical(Y_train, num_classes=10, dtype='float32')\n",
    "Y_test = to_categorical(Y_test, num_classes=10, dtype='float32')\n",
    "\n",
    "# Print details of the reshaped data\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n",
    "# Create an image generator class\n",
    "imgGentrain = ImageDataGenerator()\n",
    "\n",
    "imgGentest = ImageDataGenerator()\n",
    "\n",
    "train_batch = imgGentrain.flow(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=1)\n",
    "test_batch = imgGentest.flow(\n",
    "    x=X_test,\n",
    "    y=Y_test,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 3    # just some image for preview\n",
    "plt.imshow(X_train[index, :, :, 0])\n",
    "print(\"y = \" + str(np.squeeze(Y_train[index, :])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 2.2605 - acc: 0.2091 - val_loss: 1.8898 - val_acc: 0.3600\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.6496 - acc: 0.4774 - val_loss: 1.5598 - val_acc: 0.4880\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.2801 - acc: 0.5938 - val_loss: 1.4129 - val_acc: 0.4970\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 1.0078 - acc: 0.7090 - val_loss: 1.0580 - val_acc: 0.6640\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.8166 - acc: 0.7725 - val_loss: 0.8752 - val_acc: 0.7470\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6667 - acc: 0.8388 - val_loss: 0.8234 - val_acc: 0.7770\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.5593 - acc: 0.8682 - val_loss: 0.7035 - val_acc: 0.8030\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.4617 - acc: 0.9082 - val_loss: 0.5838 - val_acc: 0.8690\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.3763 - acc: 0.9444 - val_loss: 0.5727 - val_acc: 0.8470\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 0.3349 - acc: 0.9512 - val_loss: 0.5156 - val_acc: 0.8580\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.2957 - acc: 0.9648 - val_loss: 0.5010 - val_acc: 0.8660\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.2311 - acc: 0.9805 - val_loss: 0.4328 - val_acc: 0.9020\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.1870 - acc: 0.9844 - val_loss: 0.3920 - val_acc: 0.9160\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.1787 - acc: 0.9922 - val_loss: 0.3942 - val_acc: 0.9090\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.1591 - acc: 0.9932 - val_loss: 0.3401 - val_acc: 0.9200\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.1414 - acc: 0.9912 - val_loss: 0.3318 - val_acc: 0.9250\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.1232 - acc: 0.9961 - val_loss: 0.3611 - val_acc: 0.9080\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.1163 - acc: 0.9951 - val_loss: 0.3240 - val_acc: 0.9240\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 0.0952 - acc: 0.9971 - val_loss: 0.2949 - val_acc: 0.9370\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0802 - acc: 1.0000 - val_loss: 0.2626 - val_acc: 0.9480\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.0752 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.9310\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.0713 - acc: 1.0000 - val_loss: 0.2600 - val_acc: 0.9350\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 0.0659 - acc: 1.0000 - val_loss: 0.2819 - val_acc: 0.9360\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.0575 - acc: 1.0000 - val_loss: 0.2531 - val_acc: 0.9430\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.0538 - acc: 1.0000 - val_loss: 0.2334 - val_acc: 0.9490\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 2s 63ms/step - loss: 0.0467 - acc: 1.0000 - val_loss: 0.2362 - val_acc: 0.9480\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.0439 - acc: 1.0000 - val_loss: 0.2625 - val_acc: 0.9380\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0409 - acc: 1.0000 - val_loss: 0.2344 - val_acc: 0.9360\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0372 - acc: 1.0000 - val_loss: 0.2222 - val_acc: 0.9510\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.0358 - acc: 1.0000 - val_loss: 0.2342 - val_acc: 0.9440\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 0.0354 - acc: 1.0000 - val_loss: 0.2249 - val_acc: 0.9400\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.2303 - val_acc: 0.9490\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.2249 - val_acc: 0.9370\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.1998 - val_acc: 0.9550\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.2466 - val_acc: 0.9410\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.2052 - val_acc: 0.9510\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.1978 - val_acc: 0.9490\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.2277 - val_acc: 0.9420\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.2206 - val_acc: 0.9380\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.9480\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.2198 - val_acc: 0.9410\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.1874 - val_acc: 0.9480\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.1897 - val_acc: 0.9500\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2123 - val_acc: 0.9380\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.1971 - val_acc: 0.9520\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.9430\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.2157 - val_acc: 0.9430\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 0.9460\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.2028 - val_acc: 0.9440\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.1994 - val_acc: 0.9410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f393539cdd8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizer used = Adam\n",
    "\n",
    "# Create a model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(filters=32, kernel_size=5, strides=(1, 1), padding='valid', input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# 2. Add a convolution layer\n",
    "model.add(Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "    \n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "optAdam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "model.compile(optimizer=optAdam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_batch,\n",
    "    steps_per_epoch=len(train_batch),\n",
    "    epochs=50,\n",
    "    validation_data=test_batch,\n",
    "    validation_steps=len(test_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 63ms/step - loss: 2.2118 - acc: 0.2745 - val_loss: 1.6098 - val_acc: 0.4990\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 1.4564 - acc: 0.5020 - val_loss: 1.2823 - val_acc: 0.6070\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 2s 65ms/step - loss: 1.0719 - acc: 0.6604 - val_loss: 0.9965 - val_acc: 0.6960\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.7925 - acc: 0.7752 - val_loss: 0.9423 - val_acc: 0.6720\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.6159 - acc: 0.8319 - val_loss: 0.6634 - val_acc: 0.7960\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.4723 - acc: 0.8789 - val_loss: 0.6284 - val_acc: 0.7860\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.3584 - acc: 0.9112 - val_loss: 0.4666 - val_acc: 0.8680\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.2868 - acc: 0.9335 - val_loss: 0.4435 - val_acc: 0.8720\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.2252 - acc: 0.9599 - val_loss: 0.4207 - val_acc: 0.8810\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.1802 - acc: 0.9648 - val_loss: 0.3390 - val_acc: 0.9070\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.1531 - acc: 0.9687 - val_loss: 0.3616 - val_acc: 0.8820\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.1126 - acc: 0.9834 - val_loss: 0.3105 - val_acc: 0.9070\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.1069 - acc: 0.9845 - val_loss: 0.2799 - val_acc: 0.9180\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.0794 - acc: 0.9892 - val_loss: 0.2450 - val_acc: 0.9300\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0673 - acc: 0.9922 - val_loss: 0.2650 - val_acc: 0.9220\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0540 - acc: 0.9971 - val_loss: 0.2090 - val_acc: 0.9400\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0442 - acc: 0.9980 - val_loss: 0.1991 - val_acc: 0.9370\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0423 - acc: 0.9951 - val_loss: 0.1516 - val_acc: 0.9600\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0303 - acc: 0.9980 - val_loss: 0.1782 - val_acc: 0.9490\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0241 - acc: 0.9980 - val_loss: 0.1502 - val_acc: 0.9590\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0212 - acc: 0.9990 - val_loss: 0.1671 - val_acc: 0.9460\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.2818 - val_acc: 0.9090\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0241 - acc: 0.9932 - val_loss: 0.1461 - val_acc: 0.9610\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0134 - acc: 0.9990 - val_loss: 0.1331 - val_acc: 0.9600\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.1533 - val_acc: 0.9550\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.1243 - val_acc: 0.9590\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.1260 - val_acc: 0.9620\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0113 - acc: 0.9980 - val_loss: 0.1377 - val_acc: 0.9520\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9590\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0121 - acc: 0.9971 - val_loss: 0.1274 - val_acc: 0.9640\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1363 - val_acc: 0.9590\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.1265 - val_acc: 0.9600\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9600\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0168 - acc: 0.9961 - val_loss: 0.1610 - val_acc: 0.9540\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 0.9660\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 9.3243e-04 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9530\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0054 - acc: 0.9990 - val_loss: 0.1261 - val_acc: 0.9650\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1858 - val_acc: 0.9440\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0097 - acc: 0.9980 - val_loss: 0.1411 - val_acc: 0.9600\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 8.1701e-04 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9360\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9640\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2074 - val_acc: 0.9330\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1359 - val_acc: 0.9610\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9690\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 6.3236e-04 - acc: 1.0000 - val_loss: 0.1356 - val_acc: 0.9630\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 3.6064e-04 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9640\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.0053 - acc: 0.9980 - val_loss: 0.1604 - val_acc: 0.9540\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.6163e-04 - acc: 1.0000 - val_loss: 0.1474 - val_acc: 0.9570\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.0086 - acc: 0.9971 - val_loss: 0.1405 - val_acc: 0.9660\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 3.6608e-04 - acc: 1.0000 - val_loss: 0.1223 - val_acc: 0.9610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3936284da0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimizer used = RMSprop\n",
    "\n",
    "# Create a model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(filters=32, kernel_size=5, strides=(1, 1), padding='valid', input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# 2. Add a convolution layer\n",
    "model.add(Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "    \n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "optRMSprop = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(optimizer=optRMSprop,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_batch,\n",
    "    steps_per_epoch=len(train_batch),\n",
    "    epochs=50,\n",
    "    validation_data=test_batch,\n",
    "    validation_steps=len(test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 63ms/step - loss: 2.7853 - acc: 0.2127 - val_loss: 2.6832 - val_acc: 0.2680\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.6452 - acc: 0.4499 - val_loss: 1.4946 - val_acc: 0.4920\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 1.1415 - acc: 0.6329 - val_loss: 1.1992 - val_acc: 0.5950\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 0.9281 - acc: 0.7041 - val_loss: 1.0113 - val_acc: 0.6800\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 0.7510 - acc: 0.7674 - val_loss: 0.9052 - val_acc: 0.6980\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6175 - acc: 0.8290 - val_loss: 0.8505 - val_acc: 0.7240\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 0.5605 - acc: 0.8419 - val_loss: 0.7326 - val_acc: 0.7730\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.4329 - acc: 0.8906 - val_loss: 0.6450 - val_acc: 0.8010\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.3737 - acc: 0.9073 - val_loss: 0.7340 - val_acc: 0.7460\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.3422 - acc: 0.9141 - val_loss: 0.5190 - val_acc: 0.8470\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.3264 - acc: 0.9238 - val_loss: 0.6195 - val_acc: 0.7890\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 0.2627 - acc: 0.9443 - val_loss: 0.5039 - val_acc: 0.8360\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2514 - acc: 0.9550 - val_loss: 0.4980 - val_acc: 0.8340\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2034 - acc: 0.9697 - val_loss: 0.4313 - val_acc: 0.8760\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1817 - acc: 0.9726 - val_loss: 0.4078 - val_acc: 0.8760\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1542 - acc: 0.9775 - val_loss: 0.4335 - val_acc: 0.8520\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1274 - acc: 0.9883 - val_loss: 0.3545 - val_acc: 0.8910\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1098 - acc: 0.9941 - val_loss: 0.3618 - val_acc: 0.8930\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1016 - acc: 0.9922 - val_loss: 0.3660 - val_acc: 0.8870\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0958 - acc: 0.9932 - val_loss: 0.3316 - val_acc: 0.8900\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0754 - acc: 0.9990 - val_loss: 0.3034 - val_acc: 0.9090\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0644 - acc: 0.9980 - val_loss: 0.2978 - val_acc: 0.9090\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0693 - acc: 0.9990 - val_loss: 0.3400 - val_acc: 0.9030\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0730 - acc: 1.0000 - val_loss: 0.3257 - val_acc: 0.9010\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0588 - acc: 1.0000 - val_loss: 0.3091 - val_acc: 0.9030\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0514 - acc: 0.9990 - val_loss: 0.2868 - val_acc: 0.9120\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0497 - acc: 0.9990 - val_loss: 0.2933 - val_acc: 0.9120\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0405 - acc: 1.0000 - val_loss: 0.2891 - val_acc: 0.9000\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0387 - acc: 1.0000 - val_loss: 0.2695 - val_acc: 0.9160\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.2540 - val_acc: 0.9260\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.2618 - val_acc: 0.9190\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 0.2742 - val_acc: 0.9130\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0296 - acc: 1.0000 - val_loss: 0.2622 - val_acc: 0.9190\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.2696 - val_acc: 0.9070\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.2470 - val_acc: 0.9210\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.2783 - val_acc: 0.9100\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.2390 - val_acc: 0.9180\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.2676 - val_acc: 0.9160\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.2462 - val_acc: 0.9250\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.2445 - val_acc: 0.9150\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.2545 - val_acc: 0.9170\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.2672 - val_acc: 0.9120\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.2614 - val_acc: 0.9180\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.2361 - val_acc: 0.9240\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.2487 - val_acc: 0.9190\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.2475 - val_acc: 0.9190\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.2408 - val_acc: 0.9210\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.2526 - val_acc: 0.9160\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.2482 - val_acc: 0.9150\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.2402 - val_acc: 0.9270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3934d3fcc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimizer used = SGDM\n",
    "\n",
    "# Create a model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(filters=32, kernel_size=5, strides=(1, 1), padding='valid', input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# 2. Add a convolution layer\n",
    "model.add(Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "    \n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "optSGD = optimizers.SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "model.compile(optimizer=optSGD,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_batch,\n",
    "    steps_per_epoch=len(train_batch),\n",
    "    epochs=50,\n",
    "    validation_data=test_batch,\n",
    "    validation_steps=len(test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
